#path to directory with .gguf files. It will be mounted with the same path inside containers
MODEL_DIR=

#configuration for llama.cpp build. should match the host CUDA version and ARCH
UBUNTU_VERSION=22.04
CUDA_VERSION=12.5.0
CUDA_DOCKER_ARCH=all

WEBUI_PORT=7777